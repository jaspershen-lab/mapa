% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/16_llm_module_RAG_strategy.R
\name{GPT_process_chunk}
\alias{GPT_process_chunk}
\title{Process Chunks with GPT for Relevance Scoring and Text Cleaning}
\usage{
GPT_process_chunk(
  chunks,
  module_list,
  api_key,
  model = "gpt-4o-mini-2024-07-18",
  api_provider = "openai",
  thinkingBudget = 0,
  thread = 10
)
}
\arguments{
\item{chunks}{A character vector where each element is a text chunk (e.g., abstracts or articles) to process.}

\item{module_list}{A list or data frame containing module information with at least:
\code{PathwayNames} (character vector) and one of \code{GeneNames_vec} or \code{MetNames_vec}
(character vectors defining molecules of interest).}

\item{api_key}{A character string containing the API key for the GPT service.}

\item{model}{A string specifying the GPT model to use (default is \code{"gpt-4o-mini-2024-07-18"}).}

\item{api_provider}{A string indicating the API provider, either \code{"openai"}, \code{"gemini"}, or \code{"siliconflow"} (default is \code{"openai"}).}

\item{thinkingBudget}{An integer for the "thinking budget" parameter specific to the Gemini API (default is \code{0}).}

\item{thread}{Integer. Number of parallel threads to use for processing.
Default is \code{10} for sequential processing.}
}
\value{
A list of results where each element is a list containing:
\item{relevance_score}{A numeric value between 0 and 1, indicating the relevance of the chunk.}
\item{cleaned_text}{A character string with unrelated information (such as author names,
affiliations, and non-relevant metadata) removed.}
The list is sorted in descending order of \code{relevance_score}.
}
\description{
Processes a list of text chunks using GPT to evaluate their relevance to a specified module
and cleans the text by removing unrelated information. The function assigns relevance scores
to each chunk based on how well it aligns with the pathways and molecules defined in the module.
}
\details{
The function performs the following steps:
\enumerate{
\item Extracts pathway and molecule information from the module_list
\item Processes each chunk in parallel using either \code{parallel::parLapply} (Windows)
or \code{pbmclapply} (other platforms)
\item For each chunk, calls the GPT API with a carefully constructed prompt
\item Validates and potentially retries the API call if the response format is incorrect
\item Parses the JSON response to extract relevance scores and cleaned text
\item Returns the results sorted by relevance score
}
}
\examples{
\dontrun{
# Example: Process a set of scientific abstracts
abstracts <- c(
  "Abstract 1: This study investigates Pathway1 and its relationship with Gene1...",
  "Abstract 2: Recent findings on Pathway2 suggest that Gene2 plays a crucial role..."
)
module_info <- list(
  PathwayNames = c("Pathway1", "Pathway2"),
  GeneNames_vec = c("Gene1", "Gene2", "Gene3")
)
api_key <- "your_openai_api_key"
results <- GPT_process_chunk(abstracts, module_info, api_key, model)

# Access the most relevant result
top_result <- results[[1]]
print(paste("Top score:", top_result$relevance_score))
print(paste("Cleaned text:", top_result$cleaned_text))
}

}
\seealso{
\code{\link{gpt_api_call}} used internally for API communication
}
\author{
Feifan Zhang \email{FEIFAN004@e.ntu.edu.sg}
}
\keyword{internal}
