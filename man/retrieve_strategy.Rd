% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/16_llm_module_RAG_strategy.R
\name{retrieve_strategy}
\alias{retrieve_strategy}
\title{Retrieve and Rerank Strategy for Modules}
\usage{
retrieve_strategy(
  pubmed_result,
  model = "gpt-4o-mini-2024-07-18",
  embedding_model = "text-embedding-3-small",
  api_key,
  similarity_filter_num = 15,
  GPT_filter_num = 5,
  local_corpus = FALSE,
  embedding_output_dir = NULL,
  save_dir_local_corpus_embed = NULL,
  api_provider = "openai",
  thinkingBudget = 0,
  thread = thread
)
}
\arguments{
\item{pubmed_result}{A named list where each element corresponds to a module,
containing \code{PathwayNames} and one of \code{GeneNames_vec} or \code{MetNames_vec}.}

\item{model}{A string specifying the GPT model to use (default is \code{"gpt-4o-mini-2024-07-18"}).}

\item{embedding_model}{A string specifying the embedding model to use (default is \code{"text-embedding-3-small"}).}

\item{api_key}{A character string containing the API key for the GPT service.}

\item{similarity_filter_num}{An integer specifying the number of top documents to keep
after similarity filtering (default is 15).}

\item{GPT_filter_num}{An integer specifying the number of top documents to keep
after GPT reranking (default is 5).}

\item{local_corpus}{A logical value indicating whether to include local documents
in the analysis (default is FALSE).}

\item{embedding_output_dir}{A character string specifying the directory for embeddings.}

\item{save_dir_local_corpus_embed}{A character string specifying the subdirectory for local
corpus embeddings (required if \code{local_corpus} is TRUE).}

\item{api_provider}{A string indicating the API provider, either \code{"openai"}, \code{"gemini"}, or \code{"siliconflow"} (default is \code{"openai"}).}

\item{thinkingBudget}{An integer for the "thinking budget" parameter specific to the Gemini API (default is \code{0}).}

\item{thread}{An integer specifying the number of parallel threads to use for processing.
Default is \code{10} for sequential processing.}
}
\value{
A named list where each element corresponds to a module. Each module contains
a list of results with the following components:
\item{title}{The title of the filtered document.}
\item{relevance_score}{The relevance score assigned by GPT.}
\item{cleaned_text}{The cleaned text returned by GPT.}
If no documents are found or processed for a module, the module's entry will be \code{NULL}.
}
\description{
Retrieves embeddings for PubMed and optionally local documents for each module,
calculates similarity scores, and uses GPT to rerank and clean the text.
}
\details{
This function performs the following steps for each module:
\enumerate{
\item Retrieves module embeddings using \code{\link{get_module_embedding}}.
\item Calculates similarity scores for PubMed and optionally local documents
using \code{\link{calculate_similarity}}.
\item Filters the top documents based on similarity scores.
\item Reads content and titles for the top documents.
\item Uses \code{\link{GPT_process_chunk}} to rerank and clean the top documents.
\item Merges and returns the top results, sorted by relevance scores.
}

Progress updates are printed to the console throughout the processing of each module.
}
\seealso{
\code{\link{get_module_embedding}},
\code{\link{read_embeddings}},
\code{\link{calculate_similarity}},
\code{\link{read_titles}},
\code{\link{read_chunks}},
\code{\link{GPT_process_chunk}}
}
\author{
Feifan Zhang \email{FEIFAN004@e.ntu.edu.sg}
}
\keyword{internal}
